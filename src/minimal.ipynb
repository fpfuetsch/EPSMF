{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load exercise-solution and student metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from os.path import exists\n",
    "from os import mkdir\n",
    "\n",
    "from shared.load import (\n",
    "    load_solution_medatadata,\n",
    "    load_student_metadata,\n",
    "    load_edit_log_data,\n",
    ")\n",
    "\n",
    "raw_solution_metadata = load_solution_medatadata()\n",
    "student_metadata = load_student_metadata()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load attempt data from edit.log (multiple entries for each attempt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edit_log_attempt_pkl_path = \"../__pkl__/edit_log_attempts.pkl\"\n",
    "\n",
    "if not exists(\"../__pkl__\"):\n",
    "    mkdir(\"../__pkl__\") # directory to store pickles (searialized data)\n",
    "\n",
    "if exists(edit_log_attempt_pkl_path):\n",
    "    attempts_el = pd.read_pickle(edit_log_attempt_pkl_path)\n",
    "else:\n",
    "    attempts_el = load_edit_log_data()\n",
    "    attempts_el.to_pickle(edit_log_attempt_pkl_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter attempt data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"loaded {attempts_el['attempt'].nunique()} attempts from edit log data\")\n",
    "\n",
    "n = attempts_el[\"attempt\"].nunique()\n",
    "attempts_el = attempts_el.groupby(\"attempt\").filter(lambda x: len(x) >= 3)\n",
    "print(f\"removed {n - attempts_el['attempt'].nunique()} attempts with less than 3 entries\")\n",
    "\n",
    "n = attempts_el[\"attempt\"].nunique()\n",
    "attempts_el = attempts_el.groupby(\"attempt\").filter(\n",
    "    lambda x: not (x[(x[\"n_tests_green\"] / (x[\"n_tests_green\"] + x[\"n_tests_red\"])) > 0.75][\"duration_effective\"] < 1).any()\n",
    ")\n",
    "print(f\"removed {n - attempts_el['attempt'].nunique()} attempts which after less than 1 minute already have > 75 % correctness\")\n",
    "\n",
    "n = attempts_el[\"attempt\"].nunique()\n",
    "attempts_el = attempts_el.groupby(\"attempt\").filter(lambda x: x[\"duration_effective\"].max() >= 1)\n",
    "print(f\"removed {n - attempts_el['attempt'].nunique()} attempts with effective duration less than 1 minute\")\n",
    "\n",
    "print(f\"{attempts_el['attempt'].nunique()} attempts left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare dataframe with metrics (single entry for each attempt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shared.prepare import prepare_solution_metadata, prepare_record_data\n",
    "\n",
    "solution_metadata, solution_metadata_grouped, solution_metadata_grouped_scaled = prepare_solution_metadata(raw_solution_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shared.extract import extract_exercise_metadata\n",
    "\n",
    "extract_exercise_metadata(attempts_el, solution_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_pickle_file_path = \"../__pkl__/dfs.pkl\"\n",
    "\n",
    "if exists(dfs_pickle_file_path):\n",
    "    dfs = pd.read_pickle(dfs_pickle_file_path)\n",
    "else:\n",
    "    _, dfs = prepare_record_data(attempts_el, solution_metadata)\n",
    "    dfs.to_pickle(dfs_pickle_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from algorithms.fit import HyperParameters, fit_and_evaluate, split_and_prepare_data\n",
    "from algorithms.models import (\n",
    "    NN_SVD_UserItemTimeBias_SplineUserBiasShift\n",
    ")\n",
    "\n",
    "data_set = dfs\n",
    "metric = \"metric_ps_a_sqrt_x_log_bounded_min_max\"\n",
    "\n",
    "train_set, test_set, meta_data = split_and_prepare_data(df=data_set, metric=metric, test_set_size=0, n_days_grouped=1)\n",
    "\n",
    "hyper_params = {\n",
    "    \"gamma\": 0.1914764221915456,\n",
    "    \"kernel_factor\": 20.0,\n",
    "    \"learning_rate\": 0.024837016310023538,\n",
    "    \"reg_param_bi\": 0.1822901581932833,\n",
    "    \"reg_param_bt\": 0.9741206785079223,\n",
    "    \"reg_param_bu\": 0.15622270691447798,\n",
    "    \"reg_param_spline_bu\": 0.7774414688511561,\n",
    "    \"reg_param_u\": 0.01,\n",
    "    \"reg_param_i\": 0.01,\n",
    "    \"matrix_i_init\": solution_metadata_grouped_scaled, # fix exercise factors\n",
    "    \"n_factors\": solution_metadata_grouped_scaled.shape[1] -1,\n",
    "}\n",
    "\n",
    "hyper_params = HyperParameters(n_iterations=75, **hyper_params)\n",
    "score, predictions, params = fit_and_evaluate(\n",
    "    model=NN_SVD_UserItemTimeBias_SplineUserBiasShift,\n",
    "    test_set=test_set,\n",
    "    train_set=train_set,\n",
    "    meta_data=meta_data,\n",
    "    hyper_params=hyper_params,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot model params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"biases_i_pd\" in params.keys():\n",
    "    biases_i_pd = params[\"biases_i_pd\"]\n",
    "    fig, axes = plt.subplots(figsize=(17, 5), dpi=300)\n",
    "    biases_i_pd_sample = biases_i_pd.sample(frac=1).sort_values(ascending=False)\n",
    "    p = axes.bar(biases_i_pd_sample.index, biases_i_pd_sample.values)\n",
    "    axes.set_title(\"Exercise-Bias\")\n",
    "    axes.bar_label(p, labels=list(map(lambda x: f\"{len(data_set[data_set['exercise'] == x])}\", biases_i_pd_sample.index)), rotation=90, padding=5)\n",
    "    axes.set_xticklabels(biases_i_pd_sample.index, rotation=90)\n",
    "    axes.set_xmargin(0.01)\n",
    "    axes.set_ymargin(0.075)\n",
    "    axes.text(\n",
    "        0.99,\n",
    "        0.95,\n",
    "        f\"$min$ = {round(biases_i_pd.min(), 3)}\\n$max$ = {round(biases_i_pd.max(),3)}\\n$\\mu$ = {round(biases_i_pd.mean(), 3)}\\n$\\sigma$ = {round(biases_i_pd.std(), 3)}\",\n",
    "        horizontalalignment=\"right\",\n",
    "        verticalalignment=\"top\",\n",
    "        transform=axes.transAxes,\n",
    "        fontsize=14,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"biases_u_pd\" in params.keys():\n",
    "    biases_u_pd = params[\"biases_u_pd\"]\n",
    "    fig, axes = plt.subplots(figsize=(17, 5), dpi=300)\n",
    "    biases_u_pd = biases_u_pd.sort_values(ascending=False)\n",
    "    p = axes.bar(biases_u_pd.index, biases_u_pd.values, label=\"User Biases\")\n",
    "    axes.set_title(\"Student-Bias\")\n",
    "    axes.set_xticklabels(biases_u_pd.index, rotation=90)\n",
    "    axes.set_xmargin(0.01)\n",
    "    axes.text(\n",
    "        0.99,\n",
    "        0.95,\n",
    "        f\"$min$ = {round(biases_u_pd.min(), 3)}\\n$max$ = {round(biases_u_pd.max(),3)}\\n$\\mu$ = {round(biases_u_pd.mean(), 3)}\\n$\\sigma$ = {round(biases_u_pd.std(), 3)}\",\n",
    "        horizontalalignment=\"right\",\n",
    "        verticalalignment=\"top\",\n",
    "        transform=axes.transAxes,\n",
    "        fontsize=14,\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "code-KXNBlifb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
